{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/redditsentiment.csv'\n",
    "reddit_data = pd.read_csv(input_file)\n",
    "reddit_data['date_only'] = pd.to_datetime(reddit_data['date_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stock_data(tickers, start_date, end_date):\n",
    "    stock_data=[]\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data=yf.download(ticker, start_date, end=end_date)\n",
    "            if not data.empty:\n",
    "                data['ticker']=ticker\n",
    "                \n",
    "                data['date_only'] = data.index.date\n",
    "\n",
    "                data.columns = [f\"{col[0]}_{col[1]}\" if isinstance(col, tuple) else col for col in data.columns]\n",
    "\n",
    "                data.rename(columns={col: 'date_only' if 'date_only' in col else col for col in data.columns}, inplace=True)\n",
    "                print(f\"Date_only column added for {ticker}.columns: {data.columns}\")\n",
    "                stock_data.append(data)\n",
    "            else:\n",
    "                print(f\"No data for {ticker}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error for {ticker}: {e}\")\n",
    "    \n",
    "    if stock_data:\n",
    "        combined_data = pd.concat(stock_data, ignore_index=True)\n",
    "        print(f\"Combined stock data columns: {combined_data.columns}\")\n",
    "    else:\n",
    "        combined_data = pd.DataFrame()  \n",
    "        print(\"No stock data fetched.\")\n",
    "\n",
    "    \n",
    "    if 'date_only' in combined_data.columns:\n",
    "        combined_data['date_only'] = pd.to_datetime(combined_data['date_only'])\n",
    "    else:\n",
    "        print(\"Warning: 'date_only' column not found in combined stock data.\")\n",
    "\n",
    "    return combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_only column added for TSLA.columns: Index(['Close_TSLA', 'High_TSLA', 'Low_TSLA', 'Open_TSLA', 'Volume_TSLA',\n",
      "       'ticker_', 'date_only'],\n",
      "      dtype='object')\n",
      "Date_only column added for GME.columns: Index(['Close_GME', 'High_GME', 'Low_GME', 'Open_GME', 'Volume_GME', 'ticker_',\n",
      "       'date_only'],\n",
      "      dtype='object')\n",
      "Date_only column added for AAPL.columns: Index(['Close_AAPL', 'High_AAPL', 'Low_AAPL', 'Open_AAPL', 'Volume_AAPL',\n",
      "       'ticker_', 'date_only'],\n",
      "      dtype='object')\n",
      "Date_only column added for NVDA.columns: Index(['Close_NVDA', 'High_NVDA', 'Low_NVDA', 'Open_NVDA', 'Volume_NVDA',\n",
      "       'ticker_', 'date_only'],\n",
      "      dtype='object')\n",
      "Combined stock data columns: Index(['Close_TSLA', 'High_TSLA', 'Low_TSLA', 'Open_TSLA', 'Volume_TSLA',\n",
      "       'ticker_', 'date_only', 'Close_GME', 'High_GME', 'Low_GME', 'Open_GME',\n",
      "       'Volume_GME', 'Close_AAPL', 'High_AAPL', 'Low_AAPL', 'Open_AAPL',\n",
      "       'Volume_AAPL', 'Close_NVDA', 'High_NVDA', 'Low_NVDA', 'Open_NVDA',\n",
      "       'Volume_NVDA'],\n",
      "      dtype='object')\n",
      "date_only column exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tickers = ['TSLA', 'GME', 'AAPL', 'NVDA']\n",
    "start_date = (datetime.now() - pd.Timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "combined_reddit_stock = scrape_stock_data(tickers, start_date, end_date)\n",
    "if 'date_only' in combined_reddit_stock.columns:\n",
    "   print('date_only column exists')\n",
    "else:\n",
    "   print('date_only column does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Close_TSLA   High_TSLA    Low_TSLA   Open_TSLA  Volume_TSLA ticker_  \\\n",
      "0  147.050003  150.940002  146.220001  148.970001   86005100.0    TSLA   \n",
      "1  142.050003  144.440002  138.800003  140.559998  107097600.0    TSLA   \n",
      "2  144.679993  147.259995  141.110001  143.330002  124545100.0    TSLA   \n",
      "3  162.130005  167.970001  157.509995  162.839996  181178000.0    TSLA   \n",
      "4  170.179993  170.880005  158.360001  158.960007  126427500.0    TSLA   \n",
      "\n",
      "   date_only  Close_GME  High_GME  Low_GME  ...  Close_AAPL  High_AAPL  \\\n",
      "0 2024-04-19        NaN       NaN      NaN  ...         NaN        NaN   \n",
      "1 2024-04-22        NaN       NaN      NaN  ...         NaN        NaN   \n",
      "2 2024-04-23        NaN       NaN      NaN  ...         NaN        NaN   \n",
      "3 2024-04-24        NaN       NaN      NaN  ...         NaN        NaN   \n",
      "4 2024-04-25        NaN       NaN      NaN  ...         NaN        NaN   \n",
      "\n",
      "   Low_AAPL  Open_AAPL  Volume_AAPL  Close_NVDA  High_NVDA  Low_NVDA  \\\n",
      "0       NaN        NaN          NaN         NaN        NaN       NaN   \n",
      "1       NaN        NaN          NaN         NaN        NaN       NaN   \n",
      "2       NaN        NaN          NaN         NaN        NaN       NaN   \n",
      "3       NaN        NaN          NaN         NaN        NaN       NaN   \n",
      "4       NaN        NaN          NaN         NaN        NaN       NaN   \n",
      "\n",
      "   Open_NVDA  Volume_NVDA  \n",
      "0        NaN          NaN  \n",
      "1        NaN          NaN  \n",
      "2        NaN          NaN  \n",
      "3        NaN          NaN  \n",
      "4        NaN          NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_reddit_stock.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reddit_stock['date_only'] = pd.to_datetime(combined_reddit_stock['date_only'], errors='coerce')\n",
    "reddit_data['date_only'] = pd.to_datetime(reddit_data['date_only'], errors='coerce')\n",
    "combined_reddit_stock['date_only'] = combined_reddit_stock['date_only'] - pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Close_TSLA   High_TSLA    Low_TSLA   Open_TSLA  Volume_TSLA ticker_  \\\n",
      "235  263.549988  276.100006  260.570007  275.579987  123809400.0    TSLA   \n",
      "\n",
      "     date_only  Close_GME  High_GME  Low_GME  ...  Close_AAPL  High_AAPL  \\\n",
      "235 2025-03-27        NaN       NaN      NaN  ...         NaN        NaN   \n",
      "\n",
      "     Low_AAPL  Open_AAPL  Volume_AAPL  Close_NVDA  High_NVDA  Low_NVDA  \\\n",
      "235       NaN        NaN          NaN         NaN        NaN       NaN   \n",
      "\n",
      "     Open_NVDA  Volume_NVDA  \n",
      "235        NaN          NaN  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data_for_day = combined_reddit_stock[combined_reddit_stock['date_only'] == '2025-03-27']\n",
    "tsla_data_for_day = data_for_day[data_for_day['ticker_'] == 'TSLA']\n",
    "print(tsla_data_for_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        subreddit              created  score  upvote_ratio  num_comments  \\\n",
      "0  wallstreetbets  2025-04-19 09:32:11     41          0.92            18   \n",
      "1  wallstreetbets  2025-04-19 07:40:37    106          0.94            70   \n",
      "2  wallstreetbets  2025-04-19 03:58:09     87          0.81            84   \n",
      "3  wallstreetbets  2025-04-18 20:35:36    163          0.91            78   \n",
      "4  wallstreetbets  2025-04-18 19:42:14   7788          0.91          1623   \n",
      "\n",
      "   has_target_stock mentioned_tickers  date_only  title_sentiment_vader  \\\n",
      "0                 0               NaN 2025-04-19                 0.2732   \n",
      "1                 0               NaN 2025-04-19                 0.3400   \n",
      "2                 0               NaN 2025-04-19                 0.4215   \n",
      "3                 0               NaN 2025-04-18                 0.3612   \n",
      "4                 0               NaN 2025-04-18                -0.4215   \n",
      "\n",
      "   post_sentiment_vader  title_sentiment_finbert  post_sentiment_finbert  \\\n",
      "0                0.0000                 0.940416                0.000000   \n",
      "1                0.9393                 0.000000                0.000000   \n",
      "2                0.0000                 0.000000                0.000000   \n",
      "3               -0.1691                 0.000000               -0.606552   \n",
      "4                0.0000                -0.812795                0.000000   \n",
      "\n",
      "   title_weight  post_weight  vader_score  finbert_score  sentiment_score  \\\n",
      "0          1.00         0.00     0.273200       0.940416         0.606808   \n",
      "1          0.75         0.25     0.489825       0.000000         0.244913   \n",
      "2          0.75         0.25     0.316125       0.000000         0.158062   \n",
      "3          0.75         0.25     0.228625      -0.151638         0.038494   \n",
      "4          0.75         0.25    -0.316125      -0.609596        -0.462861   \n",
      "\n",
      "   sentiment_normalized sentiment_category  \n",
      "0             80.340404      very_positive  \n",
      "1             62.245625           positive  \n",
      "2             57.903125           positive  \n",
      "3             51.924677            neutral  \n",
      "4             26.856963           negative  \n"
     ]
    }
   ],
   "source": [
    "print(reddit_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Close_TSLA   High_TSLA    Low_TSLA   Open_TSLA  Volume_TSLA ticker_  \\\n",
      "0  263.549988  276.100006  260.570007  275.579987  123809400.0    TSLA   \n",
      "1  263.549988  276.100006  260.570007  275.579987  123809400.0    TSLA   \n",
      "2  259.160004  260.559998  243.360001  249.309998  134008900.0    TSLA   \n",
      "3  259.160004  260.559998  243.360001  249.309998  134008900.0    TSLA   \n",
      "4  259.160004  260.559998  243.360001  249.309998  134008900.0    TSLA   \n",
      "\n",
      "   date_only  Close_GME  High_GME  Low_GME  ...  post_sentiment_vader  \\\n",
      "0 2025-03-27        NaN       NaN      NaN  ...                0.9474   \n",
      "1 2025-03-27        NaN       NaN      NaN  ...                0.7845   \n",
      "2 2025-03-30        NaN       NaN      NaN  ...                0.9813   \n",
      "3 2025-03-30        NaN       NaN      NaN  ...                0.5753   \n",
      "4 2025-03-30        NaN       NaN      NaN  ...                0.7821   \n",
      "\n",
      "   title_sentiment_finbert  post_sentiment_finbert  title_weight  post_weight  \\\n",
      "0                      0.0                     0.0          0.75         0.25   \n",
      "1                      0.0                     0.0          0.75         0.25   \n",
      "2                      0.0                     0.0          0.75         0.25   \n",
      "3                      0.0                     0.0          0.75         0.25   \n",
      "4                      0.0                     0.0          0.75         0.25   \n",
      "\n",
      "   vader_score  finbert_score  sentiment_score  sentiment_normalized  \\\n",
      "0     0.236850            0.0         0.118425             55.921250   \n",
      "1     0.196125            0.0         0.098062             54.903125   \n",
      "2     0.245325            0.0         0.122662             56.133125   \n",
      "3     0.661925            0.0         0.330962             66.548125   \n",
      "4     0.176175            0.0         0.088087             54.404375   \n",
      "\n",
      "   sentiment_category  \n",
      "0            positive  \n",
      "1             neutral  \n",
      "2            positive  \n",
      "3            positive  \n",
      "4             neutral  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "combined_reddit_stock = combined_reddit_stock.merge(lagging_dates, on='date_only', how='inner')\n",
    "print(combined_reddit_stock.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file created\n"
     ]
    }
   ],
   "source": [
    "combined_reddit_stock.drop(columns=['date_only', 'created'], inplace=True)\n",
    "output_file = '../data/stock_reddit_merge.csv'\n",
    "combined_reddit_stock.to_csv(output_file, index=False)\n",
    "print('output file created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
