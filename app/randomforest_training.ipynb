{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after loading: (89, 11)\n",
      "Columns in the dataset: ['date_only', 'posts_per_day', 'avg_sentiment', 'avg_sentiment_normalized', 'date_only_stock', 'ticker', 'Open', 'High', 'Low', 'Close', 'Volume']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/00/merged/sentiment_stock_merged_GME.csv')\n",
    "print('Shape of data after loading:', data.shape)\n",
    "print('Columns in the dataset:', data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Movement'] = data.apply(lambda row: 'up' if row['Close'] > row['Open'] else 'down', axis=1)\n",
    "\n",
    "features = [\n",
    "    'date_only', 'posts_per_day', 'avg_sentiment', 'avg_sentiment_normalized',\n",
    "    'date_only_stock', 'ticker', 'Open', 'High', 'Low', 'Close', 'Volume', 'Movement'\n",
    "]\n",
    "missing = [col for col in features if col not in data.columns]\n",
    "if missing:\n",
    "    print(f'Missing required columns: {missing}')\n",
    "    raise SystemExit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['date_only', 'date_only_stock']\n",
    "for col in date_cols:\n",
    "    data[col] = pd.to_datetime(data[col])\n",
    "    data[f'{col}_day']       = data[col].dt.day\n",
    "    data[f'{col}_month']     = data[col].dt.month\n",
    "    data[f'{col}_year']      = data[col].dt.year\n",
    "    data[f'{col}_dayofweek'] = data[col].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features to be used: ['posts_per_day', 'avg_sentiment', 'avg_sentiment_normalized', 'Open', 'High', 'Low', 'Close', 'Volume', 'date_only_day', 'date_only_month', 'date_only_year', 'date_only_dayofweek']\n",
      "X shape: (89, 12), y shape: (89,)\n"
     ]
    }
   ],
   "source": [
    "numeric_features = [\n",
    "    'posts_per_day', 'avg_sentiment', 'avg_sentiment_normalized',\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "    'date_only_day', 'date_only_month', 'date_only_year', 'date_only_dayofweek'\n",
    "]\n",
    "numeric_features = [c for c in numeric_features if c in data.columns]\n",
    "print(\"Numeric features to be used:\", numeric_features)\n",
    "\n",
    "X = data[numeric_features]\n",
    "y = data['Movement']\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values per column:\n",
      " posts_per_day               0\n",
      "avg_sentiment               0\n",
      "avg_sentiment_normalized    0\n",
      "Open                        0\n",
      "High                        0\n",
      "Low                         0\n",
      "Close                       0\n",
      "Volume                      0\n",
      "date_only_day               0\n",
      "date_only_month             0\n",
      "date_only_year              0\n",
      "date_only_dayofweek         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/r372mq11725b3qtfgx955zlr0000gn/T/ipykernel_45187/2985698186.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].fillna(X[col].mean())\n"
     ]
    }
   ],
   "source": [
    "for col in numeric_features:\n",
    "    X[col] = X[col].fillna(X[col].mean())\n",
    "print('Remaining missing values per column:\\n', X.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting randomized search...\n",
      "                                               params  mean_train_score  \\\n",
      "0   {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "1   {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "2   {'n_estimators': 1000, 'min_samples_split': 10...          0.556927   \n",
      "3   {'n_estimators': 500, 'min_samples_split': 100...          0.556927   \n",
      "4   {'n_estimators': 500, 'min_samples_split': 50,...          0.556927   \n",
      "5   {'n_estimators': 500, 'min_samples_split': 50,...          0.556927   \n",
      "6   {'n_estimators': 1000, 'min_samples_split': 10...          0.556927   \n",
      "7   {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "8   {'n_estimators': 200, 'min_samples_split': 20,...          0.556927   \n",
      "9   {'n_estimators': 1000, 'min_samples_split': 50...          0.556927   \n",
      "10  {'n_estimators': 200, 'min_samples_split': 20,...          0.556927   \n",
      "11  {'n_estimators': 1000, 'min_samples_split': 20...          0.556927   \n",
      "12  {'n_estimators': 1000, 'min_samples_split': 20...          0.556927   \n",
      "13  {'n_estimators': 1000, 'min_samples_split': 10...          0.556927   \n",
      "14  {'n_estimators': 500, 'min_samples_split': 20,...          0.669637   \n",
      "15  {'n_estimators': 1000, 'min_samples_split': 10...          0.556927   \n",
      "16  {'n_estimators': 1000, 'min_samples_split': 20...          0.556927   \n",
      "17  {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "18  {'n_estimators': 200, 'min_samples_split': 50,...          0.556927   \n",
      "19  {'n_estimators': 500, 'min_samples_split': 20,...          0.556927   \n",
      "20  {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "21  {'n_estimators': 500, 'min_samples_split': 20,...          0.556927   \n",
      "22  {'n_estimators': 200, 'min_samples_split': 20,...          0.645462   \n",
      "23  {'n_estimators': 200, 'min_samples_split': 50,...          0.556927   \n",
      "24  {'n_estimators': 1000, 'min_samples_split': 50...          0.556927   \n",
      "25  {'n_estimators': 1000, 'min_samples_split': 20...          0.661474   \n",
      "26  {'n_estimators': 500, 'min_samples_split': 20,...          0.556927   \n",
      "27  {'n_estimators': 500, 'min_samples_split': 20,...          0.556927   \n",
      "28  {'n_estimators': 200, 'min_samples_split': 50,...          0.556927   \n",
      "29  {'n_estimators': 1000, 'min_samples_split': 20...          0.556927   \n",
      "30  {'n_estimators': 200, 'min_samples_split': 50,...          0.556927   \n",
      "31  {'n_estimators': 500, 'min_samples_split': 20,...          0.669637   \n",
      "32  {'n_estimators': 500, 'min_samples_split': 100...          0.556927   \n",
      "33  {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "34  {'n_estimators': 200, 'min_samples_split': 20,...          0.556927   \n",
      "35  {'n_estimators': 200, 'min_samples_split': 20,...          0.556927   \n",
      "36  {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "37  {'n_estimators': 500, 'min_samples_split': 100...          0.556927   \n",
      "38  {'n_estimators': 1000, 'min_samples_split': 20...          0.661474   \n",
      "39  {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "40  {'n_estimators': 200, 'min_samples_split': 50,...          0.556927   \n",
      "41  {'n_estimators': 200, 'min_samples_split': 20,...          0.556927   \n",
      "42  {'n_estimators': 500, 'min_samples_split': 50,...          0.556927   \n",
      "43  {'n_estimators': 500, 'min_samples_split': 100...          0.556927   \n",
      "44  {'n_estimators': 200, 'min_samples_split': 100...          0.556927   \n",
      "45  {'n_estimators': 500, 'min_samples_split': 50,...          0.556927   \n",
      "46  {'n_estimators': 1000, 'min_samples_split': 50...          0.556927   \n",
      "47  {'n_estimators': 1000, 'min_samples_split': 20...          0.556927   \n",
      "48  {'n_estimators': 200, 'min_samples_split': 20,...          0.556927   \n",
      "49  {'n_estimators': 500, 'min_samples_split': 100...          0.556927   \n",
      "\n",
      "    mean_test_score       gap  \n",
      "0          0.581818 -0.024892  \n",
      "1          0.581818 -0.024892  \n",
      "2          0.581818 -0.024892  \n",
      "3          0.581818 -0.024892  \n",
      "4          0.581818 -0.024892  \n",
      "5          0.581818 -0.024892  \n",
      "6          0.581818 -0.024892  \n",
      "7          0.581818 -0.024892  \n",
      "8          0.581818 -0.024892  \n",
      "9          0.581818 -0.024892  \n",
      "10         0.581818 -0.024892  \n",
      "11         0.581818 -0.024892  \n",
      "12         0.581818 -0.024892  \n",
      "13         0.581818 -0.024892  \n",
      "14         0.581818  0.087819  \n",
      "15         0.581818 -0.024892  \n",
      "16         0.581818 -0.024892  \n",
      "17         0.581818 -0.024892  \n",
      "18         0.581818 -0.024892  \n",
      "19         0.581818 -0.024892  \n",
      "20         0.581818 -0.024892  \n",
      "21         0.581818 -0.024892  \n",
      "22         0.581818  0.063644  \n",
      "23         0.581818 -0.024892  \n",
      "24         0.581818 -0.024892  \n",
      "25         0.618182  0.043292  \n",
      "26         0.581818 -0.024892  \n",
      "27         0.581818 -0.024892  \n",
      "28         0.581818 -0.024892  \n",
      "29         0.581818 -0.024892  \n",
      "30         0.581818 -0.024892  \n",
      "31         0.581818  0.087819  \n",
      "32         0.581818 -0.024892  \n",
      "33         0.581818 -0.024892  \n",
      "34         0.581818 -0.024892  \n",
      "35         0.581818 -0.024892  \n",
      "36         0.581818 -0.024892  \n",
      "37         0.581818 -0.024892  \n",
      "38         0.618182  0.043292  \n",
      "39         0.581818 -0.024892  \n",
      "40         0.581818 -0.024892  \n",
      "41         0.581818 -0.024892  \n",
      "42         0.581818 -0.024892  \n",
      "43         0.581818 -0.024892  \n",
      "44         0.581818 -0.024892  \n",
      "45         0.581818 -0.024892  \n",
      "46         0.581818 -0.024892  \n",
      "47         0.581818 -0.024892  \n",
      "48         0.581818 -0.024892  \n",
      "49         0.581818 -0.024892  \n",
      "Best Hyperparameters: {'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':      [200, 500, 1000],\n",
    "    'max_depth':         [2, 3, 5],\n",
    "    'min_samples_split': [20, 50, 100],\n",
    "    'min_samples_leaf':  [10,20, 50],\n",
    "    'max_features':      ['sqrt', 'log2', 0.3]\n",
    "}\n",
    "print(\"Starting randomized search...\")\n",
    "rand_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        oob_score=True,\n",
    "        bootstrap=True\n",
    "    ),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame(rand_search.cv_results_)\n",
    "results['gap'] = results['mean_train_score'] - results['mean_test_score']\n",
    "print(results[['params', 'mean_train_score', 'mean_test_score', 'gap']])\n",
    "\n",
    "best_model = rand_search.best_estimator_\n",
    "print('Best Hyperparameters:', rand_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Precision: 0.14285714285714285\n",
      "Recall: 0.25\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        down       0.73      0.57      0.64        14\n",
      "          up       0.14      0.25      0.18         4\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.44      0.41      0.41        18\n",
      "weighted avg       0.60      0.50      0.54        18\n",
      "\n",
      "Confusion Matrix:\n",
      " [[8 6]\n",
      " [3 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, pos_label='up'))\n",
    "print('Recall:',    recall_score(y_test, y_pred, pos_label='up'))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      " date_only_dayofweek         0.191773\n",
      "Open                        0.134331\n",
      "Close                       0.131930\n",
      "Volume                      0.125679\n",
      "High                        0.114705\n",
      "Low                         0.100593\n",
      "avg_sentiment_normalized    0.065231\n",
      "avg_sentiment               0.059080\n",
      "posts_per_day               0.037499\n",
      "date_only_day               0.024257\n",
      "date_only_month             0.012538\n",
      "date_only_year              0.002384\n",
      "dtype: float64\n",
      "\n",
      "Cross-validation accuracy: 0.6072 ± 0.0577\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Feature Importances & Cross‑Validation\n",
    "importances = pd.Series(best_model.feature_importances_, index=numeric_features)\n",
    "print(\"Feature Importances:\\n\", importances.sort_values(ascending=False))\n",
    "\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5)\n",
    "print(f\"\\nCross-validation accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RedditStocksV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
