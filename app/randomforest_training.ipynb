{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder # For 'subreddit' or 'ticker'\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (35, 12)\n",
      "Columns: ['date_only', 'ticker', 'Open', 'High', 'Low', 'Close', 'Volume', 'Movement', 'mean_sentiment_score', 'mean_vader_score', 'mean_finbert_score', 'post_count']\n",
      "Data sample:\n",
      "     date_only ticker        Open        High         Low       Close  \\\n",
      "23 2025-03-31   NVDA  105.129997  110.959999  103.650002  108.379997   \n",
      "0  2025-04-01   TSLA  263.799988  277.450012  259.250000  268.459991   \n",
      "24 2025-04-01   NVDA  108.519997  110.199997  106.470001  110.150002   \n",
      "13 2025-04-01   AAPL  219.809998  223.679993  218.899994  223.190002   \n",
      "1  2025-04-02   TSLA  254.600006  284.989990  251.270004  282.760010   \n",
      "\n",
      "       Volume  Movement  mean_sentiment_score  mean_vader_score  \\\n",
      "23  299212700         1             -0.034150          -0.06830   \n",
      "0   146486900         1              0.363325           0.72665   \n",
      "24  222614000         1              0.242775           0.48555   \n",
      "13   36412700         1              0.081800           0.16360   \n",
      "1   212787800         1              0.014390           0.02878   \n",
      "\n",
      "    mean_finbert_score  post_count  \n",
      "23                 0.0           1  \n",
      "0                  0.0           1  \n",
      "24                 0.0           2  \n",
      "13                 0.0           1  \n",
      "1                  0.0           5  \n",
      "Check for NaNs:\n",
      " date_only               0\n",
      "ticker                  0\n",
      "Open                    0\n",
      "High                    0\n",
      "Low                     0\n",
      "Close                   0\n",
      "Volume                  0\n",
      "Movement                0\n",
      "mean_sentiment_score    0\n",
      "mean_vader_score        0\n",
      "mean_finbert_score      0\n",
      "post_count              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Use the correctly merged and lagged file\n",
    "data_file = '../data/stock_reddit_merged_lagged_corrected.csv'\n",
    "data = pd.read_csv(data_file)\n",
    "\n",
    "# Convert date_only to datetime if needed for sorting\n",
    "data['date_only'] = pd.to_datetime(data['date_only'])\n",
    "data = data.sort_values('date_only')\n",
    "\n",
    "print(f\"Loaded data shape: {data.shape}\")\n",
    "print(\"Columns:\", data.columns.tolist())\n",
    "print(\"Data sample:\\n\", data.head())\n",
    "print(\"Check for NaNs:\\n\", data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tickers in data: ['NVDA' 'TSLA' 'AAPL' 'GME']\n",
      "Features (X) shape: (12, 9)\n",
      "Target (y) shape: (12,)\n"
     ]
    }
   ],
   "source": [
    " # Define Target (should already be 'Movement' from the merge script)\n",
    "target = 'Movement'\n",
    "\n",
    "# Define Features\n",
    "# SELECT FEATURES CAREFULLY TO AVOID LEAKAGE\n",
    "# Example: Use aggregated sentiment, post count, and SAME DAY OHLCV for the SPECIFIC ticker\n",
    "# Avoid using OHLCV from OTHER tickers for the same day unless properly lagged.\n",
    "\n",
    "# Get unique tickers to potentially build per-ticker models or use 'ticker' as a feature\n",
    "unique_tickers = data['ticker'].unique()\n",
    "print(f\"Unique tickers in data: {unique_tickers}\")\n",
    "\n",
    "# For this example, let's predict for NVDA and use NVDA's data + sentiment\n",
    "# If you want a general model, 'ticker' could be a feature (needs one-hot encoding)\n",
    "data_predict_ticker = data[data['ticker'] == 'NVDA'].copy() # Example: Filter for one ticker\n",
    "if data_predict_ticker.empty:\n",
    "     raise ValueError(\"No data found for the specified ticker 'NVDA'. Check the merged data.\")\n",
    "\n",
    "\n",
    "# Define feature columns for the chosen ticker model\n",
    "# Features are from day D, Target ('Movement') is derived from day D+1\n",
    "numeric_features = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', # Stock data for NVDA on day D\n",
    "    'mean_sentiment_score', 'mean_vader_score', # Aggregated sentiment for NVDA on day D\n",
    "    'mean_finbert_score', 'post_count'         # Aggregated sentiment for NVDA on day D\n",
    "]\n",
    "# Add categorical features if applicable (e.g., 'subreddit' if aggregated)\n",
    "# categorical_features = ['subreddit_agg'] # Example if you aggregated subreddit info\n",
    "\n",
    "# Ensure all selected features exist\n",
    "missing_features = [f for f in numeric_features if f not in data_predict_ticker.columns]\n",
    "if missing_features:\n",
    "    raise ValueError(f\"Missing required feature columns: {missing_features}\")\n",
    "\n",
    "X = data_predict_ticker[numeric_features]\n",
    "y = data_predict_ticker[target]\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation set size: 9\n",
      "Hold-out Test set size: 3\n"
     ]
    }
   ],
   "source": [
    "# Use TimeSeriesSplit for realistic evaluation\n",
    "n_splits = 5 # Number of splits for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Optional: Define a final hold-out test set (e.g., last 20% of time)\n",
    "test_size_percentage = 0.20\n",
    "split_index = int(len(X) * (1 - test_size_percentage))\n",
    "X_train_val, X_test = X[:split_index], X[split_index:]\n",
    "y_train_val, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f\"Train/Validation set size: {len(X_train_val)}\")\n",
    "print(f\"Hold-out Test set size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaNs and Scale features AFTER splitting\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # Impute NaNs\n",
    "    ('scaler', StandardScaler()) # Scale features\n",
    "])\n",
    "\n",
    "# If you had categorical features:\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# Combine transformers\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "#         #('cat', categorical_transformer, categorical_features) # Uncomment if using categorical\n",
    "#     ])\n",
    "\n",
    "# Using only numeric features in this example\n",
    "preprocessor = numeric_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search CV with TimeSeriesSplit...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Hyperparameters:  {'classifier__max_depth': 5, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 3, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Create the full pipeline including preprocessing and classifier\n",
    "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# Define parameter grid (adjust based on compute resources and desired thoroughness)\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100], # Reduced for speed\n",
    "    'classifier__max_depth': [5, 10, None],\n",
    "    'classifier__min_samples_split': [5, 10],\n",
    "    'classifier__min_samples_leaf': [3, 5],\n",
    "    'classifier__max_features': ['sqrt', 0.5], # Use float for percentage\n",
    "    # 'classifier__ccp_alpha': [0.0, 0.001] # CCP Pruning\n",
    "}\n",
    "\n",
    "# Use TimeSeriesSplit in GridSearchCV\n",
    "grid_search = GridSearchCV(rf_pipeline, param_grid, cv=tscv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Starting Grid Search CV with TimeSeriesSplit...\")\n",
    "# Fit on the training/validation part of the data\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "\n",
    "print('Best Hyperparameters: ', grid_search.best_params_)\n",
    "best_model_pipeline = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time-Series Cross-Validated Accuracy (on train/val data): 0.6000 +/- 0.4899\n",
      "\n",
      "Evaluating best model on the hold-out test set...\n",
      "\n",
      "Hold-Out Test Set Performance:\n",
      "Accuracy:  0.0000\n",
      "Precision (for class 1): 0.0000\n",
      "Recall (for class 1):    0.0000\n",
      "\n",
      "Classification Report (Test Set):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Down/NoChange       0.00      0.00      0.00       3.0\n",
      "           Up       0.00      0.00      0.00       0.0\n",
      "\n",
      "     accuracy                           0.00       3.0\n",
      "    macro avg       0.00      0.00      0.00       3.0\n",
      " weighted avg       0.00      0.00      0.00       3.0\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "[[0 3]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "# A. Cross-Validation Score (using TimeSeriesSplit on train/validation data)\n",
    "# Refit CV on the train/validation set to get a score distribution\n",
    "cv_scores = cross_val_score(best_model_pipeline, X_train_val, y_train_val, cv=tscv, scoring='accuracy')\n",
    "print(f'\\nTime-Series Cross-Validated Accuracy (on train/val data): {np.mean(cv_scores):.4f} +/- {np.std(cv_scores):.4f}')\n",
    "\n",
    "# B. Final Evaluation on Hold-Out Test Set\n",
    "print(\"\\nEvaluating best model on the hold-out test set...\")\n",
    "y_pred_test = best_model_pipeline.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "# Specify labels for precision/recall if target is binary (0, 1)\n",
    "# Use zero_division=0 to avoid warnings if a class has no predicted samples\n",
    "precision_test = precision_score(y_test, y_pred_test, labels=[0, 1], average='binary', pos_label=1, zero_division=0)\n",
    "recall_test = recall_score(y_test, y_pred_test, labels=[0, 1], average='binary', pos_label=1, zero_division=0)\n",
    "\n",
    "print('\\nHold-Out Test Set Performance:')\n",
    "print(f'Accuracy:  {accuracy_test:.4f}')\n",
    "print(f'Precision (for class 1): {precision_test:.4f}')\n",
    "print(f'Recall (for class 1):    {recall_test:.4f}')\n",
    "\n",
    "print('\\nClassification Report (Test Set):')\n",
    "print(classification_report(y_test, y_pred_test, labels=[0, 1], target_names=['Down/NoChange', 'Up'], zero_division=0))\n",
    "\n",
    "print('\\nConfusion Matrix (Test Set):')\n",
    "print(confusion_matrix(y_test, y_pred_test, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                Feature  Importance\n",
      "2                   Low    0.212121\n",
      "1                  High    0.151515\n",
      "5  mean_sentiment_score    0.151515\n",
      "0                  Open    0.090909\n",
      "6      mean_vader_score    0.090909\n",
      "7    mean_finbert_score    0.090909\n",
      "8            post_count    0.090909\n",
      "3                 Close    0.060606\n",
      "4                Volume    0.060606\n"
     ]
    }
   ],
   "source": [
    "# Access the classifier step in the pipeline\n",
    "rf_model = best_model_pipeline.named_steps['classifier']\n",
    "# If you used ColumnTransformer, get feature names correctly\n",
    "# feature_names = best_model_pipeline.named_steps['preprocessor']...? # Need to get names after transform\n",
    "# For simple numeric pipeline:\n",
    "feature_names = numeric_features\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = [col for col in features if col not in data.columns]\n",
    "if missing_columns:\n",
    "    print(f'Missing required columns : {missing_columns}')\n",
    "    exit()\n",
    "\n",
    "\n",
    "y = data['Movement']\n",
    "X = data.drop(columns = ['subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric = X.select_dtypes(include=['number'])\n",
    "\n",
    "# Apply scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Time‑aware train/test split ───\n",
    "data['date'] = pd.to_datetime(data['created_day_before'])  # or reuse whichever date column survived\n",
    "df = data.sort_values('date')\n",
    "cutoff = pd.Timestamp('2025-03-31')  # train up through March 31\n",
    "train = df[df['date'] <= cutoff]\n",
    "test  = df[df['date'] >  cutoff]\n",
    "\n",
    "X_train = train.drop(['Movement','date', 'subreddit'], axis=1)\n",
    "y_train = train['Movement']\n",
    "X_test  = test .drop(['Movement','date','subreddit'], axis=1)\n",
    "y_test  = test ['Movement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 540 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/pandas/core/generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: '2025-03-27'\n\n--------------------------------------------------------------------------------\n432 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/pandas/core/generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: '2025-03-26'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m60\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccp_alpha\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m,]\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 540 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/pandas/core/generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: '2025-03-27'\n\n--------------------------------------------------------------------------------\n432 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Users/jonathanermias/miniforge3/envs/RedditStocksV2/lib/python3.8/site-packages/pandas/core/generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: '2025-03-26'\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [20,40,60],\n",
    "    'max_depth' : [5,8,10],\n",
    "    'min_samples_split' : [2,5,10],\n",
    "    'min_samples_leaf' : [5,10],\n",
    "    'max_features' : ['sqrt'],\n",
    "    'ccp_alpha' : [0.001, 0.01,]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters :  {'ccp_alpha': 0.001, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "print('Best Hyperparameters : ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='up')\n",
    "recall = recall_score(y_test, y_pred, pos_label='up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy : 0.9993961352657005\n",
      "Precision : 0.9959839357429718\n",
      "Recall : 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Model Performance')\n",
    "print(f'Accuracy : {accuracy}')\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       1.00      1.00      1.00      1408\n",
      "          up       1.00      1.00      1.00       248\n",
      "\n",
      "    accuracy                           1.00      1656\n",
      "   macro avg       1.00      1.00      1.00      1656\n",
      "weighted avg       1.00      1.00      1.00      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1407    1]\n",
      " [   0  248]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated Accuracy :  0.9288265685888174\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(best_model, X_scaled, y, cv=5, scoring='accuracy')\n",
    "print('Cross-Validated Accuracy : ',cv_scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RedditStocksV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
