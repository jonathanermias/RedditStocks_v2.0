{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stock_data(tickers, start_date, end_date):\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end   = pd.to_datetime(end_date)\n",
    "\n",
    "    # yfinance end date is exclusive, so add +1 day to include `end`\n",
    "    end_plus_one = end + timedelta(days=1)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for tkr in tickers:\n",
    "        print(f\"Downloading {tkr}: {start.date()} → {end.date()}\")\n",
    "\n",
    "        df = yf.download(\n",
    "            tkr,\n",
    "            start=start,\n",
    "            end=end_plus_one,\n",
    "            auto_adjust=False,\n",
    "            progress=False,\n",
    "            threads=False,\n",
    "        )\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"  ↳ no data returned, skipping\")\n",
    "            continue\n",
    "\n",
    "        df = (\n",
    "            df.reset_index()               # Date becomes a column\n",
    "              .rename(columns={\"Date\": \"date\"})\n",
    "              .assign(\n",
    "                  ticker=tkr,\n",
    "                  date_only=lambda x: x[\"date\"].dt.date\n",
    "              )[[\"date\", \"date_only\", \"ticker\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "        )\n",
    "\n",
    "        frames.append(df)\n",
    "\n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_master_csv(new_df, csv_path, dedupe_on=(\"date_only\", \"ticker\")):\n",
    "    \"\"\"\n",
    "    Append `new_df` into `csv_path` (create if absent) and drop duplicates\n",
    "    based on `dedupe_on` columns, keeping the NEWEST scrape for any clash.\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "\n",
    "    if csv_path.exists():\n",
    "        master   = pd.read_csv(csv_path)\n",
    "        combined = pd.concat([master, new_df], ignore_index=True)\n",
    "        combined = combined.drop_duplicates(subset=dedupe_on, keep=\"last\")\n",
    "    else:\n",
    "        combined = new_df.copy()\n",
    "\n",
    "    combined = (combined\n",
    "                .sort_values(list(dedupe_on))\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "    combined.to_csv(csv_path, index=False)\n",
    "    print(f\"✔ Saved {len(combined)} rows to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GME: 2025-02-01 → 2025-04-17\n",
      "\n",
      "Sample of scraped data:\n",
      "Price        date   date_only ticker       Open       High        Low  \\\n",
      "Ticker                                      GME        GME        GME   \n",
      "0      2025-02-03  2025-02-03    GME  25.570000  26.540001  25.500000   \n",
      "1      2025-02-04  2025-02-04    GME  25.850000  26.250000  25.799999   \n",
      "2      2025-02-05  2025-02-05    GME  25.700001  25.809999  24.900000   \n",
      "3      2025-02-06  2025-02-06    GME  24.930000  25.389999  24.530001   \n",
      "4      2025-02-07  2025-02-07    GME  24.900000  25.020000  24.600000   \n",
      "\n",
      "Price       Close   Volume  \n",
      "Ticker        GME      GME  \n",
      "0       25.889999  5740500  \n",
      "1       25.900000  3353700  \n",
      "2       24.930000  4580200  \n",
      "3       24.799999  4349500  \n",
      "4       24.730000  3403300  \n",
      "✔ Saved 53 rows to ../data/01/perstock/stockvalues_00_GME.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tickers    = [\"GME\"]\n",
    "    start_date = datetime(2025, 2, 1)\n",
    "    end_date   = datetime(2025, 4, 17)\n",
    "\n",
    "    stock_df = scrape_stock_data(tickers, start_date, end_date)\n",
    "\n",
    "    if stock_df.empty:\n",
    "        print(\"No stock data returned; nothing appended.\")\n",
    "    else:\n",
    "        print(\"\\nSample of scraped data:\")\n",
    "        print(stock_df.head())\n",
    "        append_to_master_csv(stock_df, \"../data/01/perstock/stockvalues_00_GME.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
